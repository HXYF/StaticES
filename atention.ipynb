{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1027d0d3-934f-4129-8407-fd4f8a141e4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import argparse\n",
    "import torch.nn as n\n",
    "from transformers import T5Tokenizer\n",
    "from module import Solomon\n",
    "import math\n",
    "import json\n",
    "import torch\n",
    "import random\n",
    "import datetime\n",
    "from rouge import rouge\n",
    "from bleu import compute_bleu\n",
    "from templates import exp_templates, seq_templates, topn_templates\n",
    "from torch import nn\n",
    "import pickle\n",
    "import re\n",
    "from transformers import (\n",
    "    T5ForConditionalGeneration,\n",
    "    LogitsProcessorList,\n",
    "    MinLengthLogitsProcessor,\n",
    "    NoBadWordsLogitsProcessor,\n",
    "    HammingDiversityLogitsProcessor,\n",
    "    RepetitionPenaltyLogitsProcessor,\n",
    "    BeamSearchScorer,\n",
    "    MaxLengthCriteria,\n",
    "    StoppingCriteriaList,\n",
    ")\n",
    "from transformers.modeling_outputs import BaseModelOutput\n",
    "\n",
    "import torch\n",
    "from transformers.modeling_outputs import BaseModelOutput\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import pickle\n",
    "from transformers import T5Tokenizer\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "119743a7-850f-46f2-a622-52ad5122f15c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MlpProjector(nn.Module):\n",
    "    def __init__(self, rec_size=64, llm_size=512):\n",
    "        super().__init__()\n",
    "        self.mlp_proj = nn.Sequential(\n",
    "            nn.Linear(rec_size, llm_size),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(llm_size, llm_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.mlp_proj(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13e55922-e437-4190-9fbf-8398993109c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "163cbcc9-dbeb-4e06-a572-c5f410701e2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "projector = MlpProjector().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b835ec53-8d75-46ce-ab76-6dd21d5b9075",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_version = 't5-small'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9d33a1e-ba0d-4459-a0d9-674ee21d3977",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Solomon.from_pretrained(model_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb8d799-db60-43e9-ae32-43bf735b33d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(model_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634feaa6-b73e-4a99-be39-d75713c6dfd3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['item_1', 'item_2', 'item_3', 'item_4', 'item_5']\n",
      "['item_18353', 'item_18354', 'item_18355', 'item_18356', 'item_18357']\n"
     ]
    }
   ],
   "source": [
    "# 创建一个空列表\n",
    "input_list = []\n",
    "\n",
    "# 生成从 'item_1' 到 'item_11924' 的字符串，并添加到列表中\n",
    "for i in range(1, 18358):  # 注意范围是从1到11925，因为range是左闭右开区间\n",
    "    input_list.append(f\"item_{i}\")\n",
    "\n",
    "# 打印列表的前几个元素以确认\n",
    "print(input_list[:5])  # 打印前5个元素\n",
    "print(input_list[-5:])  # 打印最后5个元素"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5ce756-0723-45b5-a27b-2cc1d34fa21b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoded_source = tokenizer(input_list, padding=True, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a886d0-2bf9-4534-b333-8a02782385bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "source_seq = encoded_source['input_ids'].contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad86151-0ec1-429b-b632-56ae6ce9073e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source_seq tensor([[2118,  834,  536,    1,    0,    0],\n",
      "        [2118,  834,  357,    1,    0,    0],\n",
      "        [2118,  834,  519,    1,    0,    0],\n",
      "        [2118,  834,  591,    1,    0,    0],\n",
      "        [2118,  834,  755,    1,    0,    0]])\n"
     ]
    }
   ],
   "source": [
    "print(\"source_seq\", source_seq[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96df92a-f111-416f-b2b4-6fabe1cfaac8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_emb = model.shared(source_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5c7d33-f53c-41e2-9b5f-d461cb801785",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sahpe torch.Size([18357, 6, 512])\n"
     ]
    }
   ],
   "source": [
    "print(\"sahpe\", text_emb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412f3540-9a34-4e1c-b276-e2b9acb29589",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "\n",
    "# Step Ⅰ: 读取数据集并解析用户-物品关系\n",
    "item_to_users = {}\n",
    "\n",
    "# 读取 sequential.txt 文件\n",
    "with open('data/beauty/sequential.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        data = list(map(int, line.strip().split()))\n",
    "        user_id = data[0] - 1  # 减 1 因为用户ID从1开始，但我们用的是索引\n",
    "        items = data[1:]\n",
    "        for item in items:\n",
    "            if item not in item_to_users:\n",
    "                item_to_users[item] = []\n",
    "            item_to_users[item].append(user_id)\n",
    "\n",
    "# Step Ⅱ: 加载用户嵌入\n",
    "with open('SASRec_user_embed.pkl', 'rb') as f:\n",
    "    user_embeddings = torch.tensor(pickle.load(f)).to(device)  # 用户嵌入，形状为 (num_users, 128)\n",
    "\n",
    "# Step Ⅲ: 创建物品的用户嵌入表示并进行融合\n",
    "fused_embeddings = [None] * len(item_to_users)  # 用于保存每个物品的融合后的用户嵌入\n",
    "\n",
    "for item, users in item_to_users.items():\n",
    "    # 获取购买该物品的所有用户的嵌入\n",
    "    item_user_emb_list = user_embeddings[users]  # 形状为 (num_users_for_item, 128)\n",
    "\n",
    "    # 对用户嵌入进行平均池化，得到物品的用户嵌入\n",
    "    if len(users) > 0:\n",
    "        item_user_emb = torch.mean(item_user_emb_list, dim=0)  # (128,)\n",
    "    else:\n",
    "        # 如果没有用户购买该物品，跳过这个物品\n",
    "        continue\n",
    "\n",
    "    # 将融合后的物品用户嵌入保存到对应的索引位置，并转换为 NumPy 格式\n",
    "    fused_embeddings[item - 1] = item_user_emb.cpu().detach().numpy()  # 减 1 使物品ID与列表索引一致\n",
    "\n",
    "# Step Ⅳ: 保存融合后的嵌入为 .pkl 文件\n",
    "with open('fused_item_user_embeddings.pkl', 'wb') as f:\n",
    "    pickle.dump(fused_embeddings, f)\n",
    "\n",
    "print(\"融合后的嵌入已保存为 fused_item_user_embeddings.pkl 文件\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3f5aaea-59bb-43c2-877e-faa74000286e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: tensor([[[-34.5000,   6.8750,   9.9375,  ..., -13.0625, -19.5000,   0.5273],\n",
      "         [-39.5000,   5.5938,  36.2500,  ..., -31.3750,  24.2500,   4.7812],\n",
      "         [-26.3750,   2.9375,   5.7812,  ...,   5.6250,  -1.0156,  -2.5156],\n",
      "         [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[-34.5000,   6.8750,   9.9375,  ..., -13.0625, -19.5000,   0.5273],\n",
      "         [-39.5000,   5.5938,  36.2500,  ..., -31.3750,  24.2500,   4.7812],\n",
      "         [-17.5000,   6.1562,  -4.2812,  ...,  -6.8750,  51.2500,  -0.2910],\n",
      "         [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[-34.5000,   6.8750,   9.9375,  ..., -13.0625, -19.5000,   0.5273],\n",
      "         [-39.5000,   5.5938,  36.2500,  ..., -31.3750,  24.2500,   4.7812],\n",
      "         [-14.9375,   5.5938, -38.5000,  ...,  -0.3125,  31.0000,  -4.4375],\n",
      "         [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[-34.5000,   6.8750,   9.9375,  ..., -13.0625, -19.5000,   0.5273],\n",
      "         [-39.5000,   5.5938,  36.2500,  ..., -31.3750,  24.2500,   4.7812],\n",
      "         [-20.1250,   4.6250, -26.6250,  ...,  -7.2500,  44.2500,  -0.7930],\n",
      "         [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[-34.5000,   6.8750,   9.9375,  ..., -13.0625, -19.5000,   0.5273],\n",
      "         [-39.5000,   5.5938,  36.2500,  ..., -31.3750,  24.2500,   4.7812],\n",
      "         [-23.3750,   6.3125, -21.2500,  ..., -19.7500,  20.8750,  -1.1328],\n",
      "         [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000]]],\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# 假设 source_seq 和 text_emb 已经定义好\n",
    "# source_seq 的形状为 (batch_size, sequence_length)\n",
    "# text_emb 的形状为 (batch_size, sequence_length, embedding_dim)\n",
    "\n",
    "# 创建掩码，排除值为 0 和 1 的元素\n",
    "mask = (source_seq != 0) & (source_seq != 1)\n",
    "\n",
    "# 初始化一个空列表来存储过滤后的嵌入向量\n",
    "filtered_text_em = []\n",
    "\n",
    "# 遍历每个样本\n",
    "for i, emb in enumerate(text_emb):\n",
    "    # 获取当前样本的掩码\n",
    "    current_mask = mask[i]\n",
    "    \n",
    "    # 找到掩码为 True 的索引\n",
    "    indices = current_mask.nonzero(as_tuple=True)[0]\n",
    "    \n",
    "    # 使用索引选择需要的嵌入向量\n",
    "    filtered_emb = emb[indices]\n",
    "    \n",
    "    # 将过滤后的嵌入向量添加到列表中\n",
    "    filtered_text_em.append(filtered_emb)\n",
    "\n",
    "# 使用 pad_sequence 对过滤后的嵌入向量进行填充，以便它们具有相同的序列长度\n",
    "padded_text_emb = pad_sequence(filtered_text_em, batch_first=True)\n",
    "\n",
    "print(\"shape:\",padded_text_emb[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "960743ed-9452-4cb2-9432-64ad188c44e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_795/2754792935.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  behavior_embeddings = torch.tensor(pickle.load(f)).to(device)  # 长度为 11925，每个元素是 (512,) 的向量\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "融合后的嵌入已保存为 fused_item_embeddings.pkl 文件\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pickle\n",
    "\n",
    "# 假设已经定义了 device, padded_text_emb, projector, 和其他必要的变量\n",
    "text_emb = padded_text_emb  # 形状为 (11925, variable, 512)\n",
    "with open('SASRec_item_embed.pkl', 'rb') as f:\n",
    "    behavior_embeddings = torch.tensor(pickle.load(f)).to(device)  # 长度为 11925，每个元素是 (512,) 的向量\n",
    "text_emb = text_emb.to(device)\n",
    "\n",
    "\n",
    "class AttentionMechanism(nn.Module):\n",
    "    def __init__(self, embedding_dim):\n",
    "        super(AttentionMechanism, self).__init__()\n",
    "        self.attention_layer = nn.Linear(embedding_dim * 2, 1)\n",
    "\n",
    "    def forward(self, text_emb, behavior_emb):\n",
    "        concat_embedding = torch.cat((text_emb, behavior_emb), dim=-1)  # (1024,)\n",
    "        concat_embedding = concat_embedding.unsqueeze(0)  # (1, 1024)\n",
    "        attention_score = torch.sigmoid(self.attention_layer(concat_embedding))  # (1, 1)\n",
    "        return attention_score.squeeze()  # (1,)\n",
    "\n",
    "attention_mechanism = AttentionMechanism(embedding_dim=512).to(device)\n",
    "fused_embeddings = []  # 用于保存融合后的嵌入\n",
    "\n",
    "for idx in range(len(text_emb)):\n",
    "    current_text_emb = text_emb[idx]  # 当前物品的文本嵌入，形状为 (variable, 512)\n",
    "    current_behavior_emb = behavior_embeddings[idx]  # 当前物品的行为嵌入，形状为 (512,)\n",
    "\n",
    "    # 移除全零行\n",
    "    non_zero_mask = current_text_emb.abs().sum(dim=1).bool()  # 创建一个布尔掩码\n",
    "    filtered_text_emb = current_text_emb[non_zero_mask]  # 使用掩码过滤出非零行\n",
    "\n",
    "    # 如果过滤后没有非零行，可以考虑使用原始的 current_text_emb 或者抛出异常\n",
    "    if filtered_text_emb.numel() == 0:\n",
    "        pooled_text_emb = torch.mean(current_text_emb, dim=0)  # (512,)\n",
    "    else:\n",
    "        pooled_text_emb = torch.mean(filtered_text_emb, dim=0)  # (512,)\n",
    "\n",
    "    attention_score = attention_mechanism(pooled_text_emb, current_behavior_emb)  # (1,)\n",
    "    fused_embedding = attention_score * pooled_text_emb + (1 - attention_score) * current_behavior_emb  # (512,)\n",
    "\n",
    "    fused_embeddings.append(fused_embedding.cpu().detach().numpy())  # 转换为numpy数组\n",
    "\n",
    "with open('fused_item_embeddings.pkl', 'wb') as f:\n",
    "    pickle.dump(fused_embeddings, f)\n",
    "\n",
    "print(\"融合后的嵌入已保存为 fused_item_embeddings.pkl 文件\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15545fb-ea9f-4382-985e-9051cd01e093",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "\n",
    "# Step Ⅰ: 加载用户特征嵌入、文本嵌入和行为嵌入\n",
    "with open('SASRec_user_embed.pkl', 'rb') as f:\n",
    "    user_emb = torch.tensor(pickle.load(f))  # 用户嵌入 (num_items, 128)\n",
    "\n",
    "text_emb = padded_text_emb  # 形状为 (11925, variable, 512)\n",
    "with open('SASRec_item_embed.pkl', 'rb') as f:\n",
    "    behavior_embeddings = torch.tensor(pickle.load(f)).to(device)  # 长度为 11925，每个元素是 (512,) 的向量\n",
    "\n",
    "# 将嵌入向量移到设备\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "text_emb = text_emb.to(device)\n",
    "behavior_embeddings = behavior_embeddings.to(device)\n",
    "user_emb = user_emb.to(device)\n",
    "behavior_embeddings = projector(behavior_embeddings)\n",
    "user_emb = projector(user_emb)\n",
    "\n",
    "# Step Ⅱ: 定义注意力机制类，考虑用户嵌入\n",
    "class AttentionMechanism(nn.Module):\n",
    "    def __init__(self, text_dim, behavior_dim, user_dim):\n",
    "        super(AttentionMechanism, self).__init__()\n",
    "        # 注意力层，输入为 text + behavior + user 嵌入，输出为一个标量权重\n",
    "        self.attention_layer = nn.Linear(text_dim + behavior_dim + user_dim, 1)\n",
    "\n",
    "    def forward(self, text_emb, behavior_emb, user_emb):\n",
    "        # 拼接文本、行为和用户嵌入\n",
    "        concat_embedding = torch.cat((text_emb, behavior_emb, user_emb), dim=-1)  # (text_dim + behavior_dim + user_dim,)\n",
    "        concat_embedding = concat_embedding.unsqueeze(0)  # (1, text_dim + behavior_dim + user_dim)\n",
    "        \n",
    "        # 通过线性层计算融合权重\n",
    "        attention_score = torch.sigmoid(self.attention_layer(concat_embedding))  # (1, 1)\n",
    "        return attention_score.squeeze()  # (1,)\n",
    "\n",
    "# 创建注意力机制实例并移动到设备\n",
    "attention_mechanism = AttentionMechanism(text_dim=512, behavior_dim=512, user_dim=512).to(device)\n",
    "\n",
    "# Step Ⅲ: 对每个物品分别进行池化、计算融合权重和融合\n",
    "fused_embeddings = []  # 用于保存融合后的嵌入\n",
    "\n",
    "for idx in range(len(text_emb)):\n",
    "    # 获取当前物品的文本嵌入和行为嵌入\n",
    "    current_text_emb = text_emb[idx]  # 当前物品的文本嵌入，形状为 (variable, 512)\n",
    "    current_behavior_emb = behavior_embeddings[idx]  # 当前物品的行为嵌入，形状为 (512,)\n",
    "\n",
    "    # 对文本嵌入进行平均池化\n",
    "    pooled_text_emb = torch.mean(current_text_emb, dim=0)  # (512,)\n",
    "\n",
    "    # 获取对应的用户嵌入（假设每个物品有其唯一的用户，索引关系）\n",
    "    user_idx = idx % len(user_emb)  # 假设物品与用户的对应关系为模运算\n",
    "    current_user_emb = user_emb[user_idx]  # 当前用户的嵌入，形状为 (128,)\n",
    "\n",
    "    # 计算个性化融合权重\n",
    "    fusion_weight = attention_mechanism(pooled_text_emb, current_behavior_emb, current_user_emb)  # (1,)\n",
    "\n",
    "    # 使用融合权重加权融合文本和行为嵌入\n",
    "    fused_embedding = fusion_weight * pooled_text_emb + (1 - fusion_weight) * current_behavior_emb  # (512,)\n",
    "\n",
    "    # 保存融合后的嵌入\n",
    "    fused_embeddings.append(fused_embedding.cpu().detach().numpy())  # 转换为numpy数组\n",
    "\n",
    "# Step Ⅳ: 保存融合后的嵌入为 .pkl 文件\n",
    "with open('fused_item_embeddings.pkl', 'wb') as f:\n",
    "    pickle.dump(fused_embeddings, f)\n",
    "\n",
    "# 打印保存的成功信息\n",
    "print(\"融合后的嵌入已保存为 fused_item_embeddings.pkl 文件\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1a9bc382-d383-4ab0-8463-5e7db8bcbd27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of fused embeddings: torch.Size([22363, 512])\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import torch\n",
    "\n",
    "# 加载嵌入向量\n",
    "with open('fused_user_embeddings.pkl', 'rb') as f:\n",
    "    fused_embeddings = pickle.load(f)\n",
    "\n",
    "# 将嵌入向量转换为 PyTorch 张量\n",
    "fused_embeddings_tensor = torch.tensor(fused_embeddings)\n",
    "\n",
    "# 查看形状\n",
    "print(\"Shape of fused embeddings:\", fused_embeddings_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47935cc3-494e-43c7-8cf7-18eaf599776e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
